{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. Library "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_3x3_bn(inp, oup, image_size, downsample=False):\n",
    "    stride = 1 if downsample == False else 2\n",
    "    return nn.Sequential(\n",
    "        nn.Conv2d(inp, oup, 3, stride, 1, bias=False),\n",
    "        nn.BatchNorm2d(oup),\n",
    "        nn.GELU()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PreNorm(nn.Module):\n",
    "    def __init__(self, dim, fn, norm):\n",
    "        super().__init__()\n",
    "        self.norm = norm(dim)\n",
    "        self.fn = fn\n",
    "\n",
    "    def forward(self, x, **kwargs):\n",
    "        return self.fn(self.norm(x), **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SE(nn.Module):\n",
    "    def __init__(self, inp, oup, expansion=0.25):\n",
    "        super().__init__()\n",
    "\n",
    "        # 1x1 í¬ê¸°ì˜ Adaptive í‰ê·  í’€ë§ì„ ìˆ˜í–‰í•˜ì—¬ ì±„ë„ë³„ í‰ê· ê°’ì„ ê³„ì‚°\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "\n",
    "        # ë‘ ê°œì˜ ì„ í˜• ë ˆì´ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ì¡°ì •\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(oup, int(inp * expansion), bias=False),  # ìž…ë ¥ ì°¨ì›ì„ ì¤„ìž„ (ì±„ë„ ì¶•ì†Œ)\n",
    "            nn.GELU(),  # í™œì„±í™” í•¨ìˆ˜ GELU ì‚¬ìš©\n",
    "            nn.Linear(int(inp * expansion), oup, bias=False),  # ë‹¤ì‹œ ì›ëž˜ ì°¨ì›ìœ¼ë¡œ ë³µêµ¬ (ì±„ë„ í™•ìž¥)\n",
    "            nn.Sigmoid()  # 0~1 ë²”ìœ„ë¡œ ì •ê·œí™”í•˜ì—¬ ì±„ë„ë³„ ì¤‘ìš”ë„ ìƒì„±\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()  # ìž…ë ¥ í…ì„œì˜ í¬ê¸°: (batch, channels, height, width)\n",
    "\n",
    "        # Global Average Poolingì„ ì ìš©í•˜ì—¬ ê° ì±„ë„ì˜ í‰ê· ê°’ì„ êµ¬í•¨ (íŠ¹ì§• ì••ì¶•)\n",
    "        y = self.avg_pool(x).view(b, c)  # (b, c, 1, 1) -> (b, c)\n",
    "\n",
    "        # ì±„ë„ë³„ ì¤‘ìš”ë„ ê³„ì‚° (Squeeze-and-Excitation ì—°ì‚°)\n",
    "        y = self.fc(y).view(b, c, 1, 1)  # ë‹¤ì‹œ (b, c, 1, 1) í˜•íƒœë¡œ ë³€í™˜\n",
    "\n",
    "        # ìž…ë ¥ íŠ¹ì„± ë§µì— ì±„ë„ë³„ ê°€ì¤‘ì¹˜ ì ìš© (ì±„ë„ë³„ ì¤‘ìš”ë„ë¥¼ ê³±í•¨)\n",
    "        return x * y  # (b, c, h, w) * (b, c, 1, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, dim, hidden_dim, dropout=0.):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(dim ,hidden_dim),\n",
    "            nn.GELU(),\n",
    "            nn.Dropout(dropout),\n",
    "            nn.Linear(hidden_dim, dim),\n",
    "            nn.Dropout(dropout)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MBConv(nn.Module):\n",
    "\n",
    "    def __init__(self, inp, oup, image_size, downsample=False, expansion=4):\n",
    "        super().__init__()\n",
    "        self.downsample = downsample\n",
    "        stride = 1 if self.downsample == False else 2\n",
    "        hidden_dim = int(inp * expansion)\n",
    "\n",
    "        if self.downsample:\n",
    "            self.pool = nn.MaxPool2d(3, 2, 1)\n",
    "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
    "\n",
    "        if expansion == 1:\n",
    "            self.conv = nn.Sequential(\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, stride,\n",
    "                          1, groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        else:\n",
    "            self.conv = nn.Sequential(\n",
    "                # pw\n",
    "                # down-sample in the first conv\n",
    "                nn.Conv2d(inp, hidden_dim, 1, stride, 0, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                # dw\n",
    "                nn.Conv2d(hidden_dim, hidden_dim, 3, 1, 1,\n",
    "                          groups=hidden_dim, bias=False),\n",
    "                nn.BatchNorm2d(hidden_dim),\n",
    "                nn.GELU(),\n",
    "                SE(inp, hidden_dim),\n",
    "                # pw-linear\n",
    "                nn.Conv2d(hidden_dim, oup, 1, 1, 0, bias=False),\n",
    "                nn.BatchNorm2d(oup),\n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.conv = PreNorm(inp, self.conv, nn.BatchNorm2d)\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample:\n",
    "            return self.proj(self.pool(x)) + self.conv(x)\n",
    "        else:\n",
    "            return x + self.conv(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, dropout=0.):\n",
    "        super().__init__()\n",
    "        \n",
    "        # ë‚´ë¶€ ì°¨ì› ê³„ì‚° (head ìˆ˜ * headë‹¹ ì°¨ì› í¬ê¸°)\n",
    "        inner_dim = dim_head * heads\n",
    "\n",
    "        # output projectionì´ í•„ìš”í•œì§€ ì—¬ë¶€ (headê°€ 1ê°œì´ê³  ì°¨ì›ì´ ê°™ë‹¤ë©´ ë¶ˆí•„ìš”)\n",
    "        project_out = not (heads == 1 and dim_head == inp)\n",
    "\n",
    "        # ì´ë¯¸ì§€ í¬ê¸° ì €ìž¥ (ih: height, iw: width)\n",
    "        self.ih, self.iw = image_size\n",
    "\n",
    "        self.heads = heads\n",
    "        self.scale = dim_head ** -0.5  # Self-Attention ì ìˆ˜ ìŠ¤ì¼€ì¼ë§ (1 / sqrt(d_k))\n",
    "\n",
    "        # ðŸ”¹ ìƒëŒ€ì  ìœ„ì¹˜ ìž„ë² ë”© í…Œì´ë¸” (Learnable Parameters)\n",
    "        self.relative_bias_table = nn.Parameter(\n",
    "            torch.zeros((2 * self.ih - 1) * (2 * self.iw - 1), heads)  # (H*W, heads)\n",
    "        )\n",
    "\n",
    "        # ðŸ”¹ ìƒëŒ€ì  ìœ„ì¹˜ ì¢Œí‘œ ìƒì„±\n",
    "        coords = torch.meshgrid((torch.arange(self.ih), torch.arange(self.iw)))  \n",
    "        coords = torch.flatten(torch.stack(coords), 1)  # ì¢Œí‘œë¥¼ íŽ¼ì³ì„œ (2, H*W) í˜•íƒœë¡œ ë³€í™˜\n",
    "\n",
    "        # ëª¨ë“  ìœ„ì¹˜ ìŒ ê°„ì˜ ìƒëŒ€ì  ìœ„ì¹˜ ê³„ì‚°\n",
    "        relative_coords = coords[:, :, None] - coords[:, None, :]  # (2, H*W, H*W)\n",
    "\n",
    "        # ìƒëŒ€ì  ìœ„ì¹˜ ê°’ì„ ì–‘ìˆ˜ë¡œ ë³€í™˜ (ì¸ë±ì‹±ì„ ìœ„í•´)\n",
    "        relative_coords[0] += self.ih - 1\n",
    "        relative_coords[1] += self.iw - 1\n",
    "        relative_coords[0] *= 2 * self.iw - 1  # ìœ„ì¹˜ ê°’ì´ ê³ ìœ í•œ ì¸ë±ìŠ¤ê°€ ë˜ë„ë¡ ë³€í™˜\n",
    "\n",
    "        # (2, H*W, H*W) -> (H*W, H*W, 2)\n",
    "        relative_coords = rearrange(relative_coords, 'c h w -> h w c')\n",
    "\n",
    "        # ìµœì¢… ìƒëŒ€ ìœ„ì¹˜ ì¸ë±ìŠ¤ ìƒì„± (flatten í›„ ì°¨ì› í™•ìž¥)\n",
    "        relative_index = relative_coords.sum(-1).flatten().unsqueeze(1)  # (H*W * H*W, 1)\n",
    "\n",
    "        # register_bufferë¥¼ ì‚¬ìš©í•´ í•™ìŠµí•˜ì§€ ì•ŠëŠ” í…ì„œë¡œ ì €ìž¥ (ëª¨ë¸ ì €ìž¥ ì‹œ í•¨ê»˜ ì €ìž¥ë¨)\n",
    "        self.register_buffer(\"relative_index\", relative_index)\n",
    "\n",
    "        # ðŸ”¹ Self-Attention Softmax\n",
    "        self.attend = nn.Softmax(dim=-1)\n",
    "\n",
    "        # ðŸ”¹ Query, Key, Value ìƒì„± (ì„ í˜• ë³€í™˜)\n",
    "        self.to_qkv = nn.Linear(inp, inner_dim * 3, bias=False)  # (batch, seq_len, inner_dim * 3)\n",
    "\n",
    "        # ðŸ”¹ ì¶œë ¥ í”„ë¡œì ì…˜ (í•„ìš” ì‹œ ì ìš©)\n",
    "        self.to_out = nn.Sequential(\n",
    "            nn.Linear(inner_dim, oup),  # ìµœì¢… ì¶œë ¥ í¬ê¸°ë¡œ ë³€í™˜\n",
    "            nn.Dropout(dropout)  # ê³¼ì í•© ë°©ì§€ë¥¼ ìœ„í•œ Dropout ì ìš©\n",
    "        ) if project_out else nn.Identity()\n",
    "\n",
    "    def forward(self, x):\n",
    "        # ðŸ”¹ Query, Key, Value ë¶„í• \n",
    "        qkv = self.to_qkv(x).chunk(3, dim=-1)  # (batch, seq_len, inner_dim) 3ê°œë¡œ ë‚˜ëˆ”\n",
    "        q, k, v = map(lambda t: rearrange(\n",
    "            t, 'b n (h d) -> b h n d', h=self.heads), qkv)  # (batch, heads, seq_len, dim_head)\n",
    "\n",
    "        # ðŸ”¹ Self-Attention Score ê³„ì‚° (Q x K^T)\n",
    "        dots = torch.matmul(q, k.transpose(-1, -2)) * self.scale  # (batch, heads, seq_len, seq_len)\n",
    "\n",
    "        # ðŸ”¹ ìƒëŒ€ì  ìœ„ì¹˜ ìž„ë² ë”© ì ìš©\n",
    "        relative_bias = self.relative_bias_table.gather(\n",
    "            0, self.relative_index.repeat(1, self.heads)  # ìƒëŒ€ì  ìœ„ì¹˜ì— í•´ë‹¹í•˜ëŠ” bias ì„ íƒ\n",
    "        )\n",
    "\n",
    "        # (H*W * H*W, heads) -> (1, heads, H*W, H*W)\n",
    "        relative_bias = rearrange(\n",
    "            relative_bias, '(h w) c -> 1 c h w', h=self.ih*self.iw, w=self.ih*self.iw\n",
    "        )\n",
    "\n",
    "        # ì–´í…ì…˜ ì ìˆ˜ì— ìƒëŒ€ì  ìœ„ì¹˜ ìž„ë² ë”© ì¶”ê°€\n",
    "        dots = dots + relative_bias\n",
    "\n",
    "        # ðŸ”¹ Softmaxë¥¼ í†µí•´ ì–´í…ì…˜ ê°€ì¤‘ì¹˜ ê³„ì‚°\n",
    "        attn = self.attend(dots)\n",
    "\n",
    "        # ðŸ”¹ ì–´í…ì…˜ ì ìš© (Vì™€ ê³±í•¨)\n",
    "        out = torch.matmul(attn, v)  # (batch, heads, seq_len, dim_head)\n",
    "\n",
    "        # ðŸ”¹ ë³‘í•© (multi-head -> single representation)\n",
    "        out = rearrange(out, 'b h n d -> b n (h d)')  # (batch, seq_len, inner_dim)\n",
    "\n",
    "        # ðŸ”¹ ìµœì¢… ì¶œë ¥ ë³€í™˜\n",
    "        out = self.to_out(out)  # (batch, seq_len, oup)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Transformer(nn.Module):\n",
    "\n",
    "    def __init__(self, inp, oup, image_size, heads=8, dim_head=32, downsample=False, dropout=0.):\n",
    "        super().__init__()\n",
    "        hidden_dim = int(inp * 4)\n",
    "\n",
    "        self.ih, self.iw = image_size\n",
    "        self.downsample = downsample \n",
    "\n",
    "        if self.downsample:\n",
    "            self.pool1 = nn.MaxPool2d(3,2,1)\n",
    "            self.pool2 = nn.MaxPool2d(3,2,1)\n",
    "            self.proj = nn.Conv2d(inp, oup, 1, 1, 0, bias=False)\n",
    "\n",
    "        self.attn = Attention(inp, oup, image_size, heads, dim_head, dropout)\n",
    "        self.ff = FeedForward(oup, hidden_dim, dropout)\n",
    "\n",
    "        self.attn = nn.Sequential(\n",
    "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
    "            PreNorm(inp, self.attn, nn.LayerNorm),\n",
    "            Rearrange('b (ih iw ) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
    "        )\n",
    "\n",
    "        self.ff = nn.Sequential(\n",
    "            Rearrange('b c ih iw -> b (ih iw) c'),\n",
    "            PreNorm(oup, self.ff, nn.LayerNorm),\n",
    "            Rearrange('b (ih iw) c -> b c ih iw', ih=self.ih, iw=self.iw)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.downsample:\n",
    "            x = self.proj(self.pool1(x)) + self.attn(self.pool2(x))\n",
    "        else:\n",
    "            x = x + self.attn(x)\n",
    "\n",
    "        x = x + self.ff(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. ëª¨í˜•"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CoAtNet(nn.Module):\n",
    "    def __init__(self, image_size, in_channels, num_blocks, channels, num_classes=1000, block_types=['C', 'C', 'T', 'T']):\n",
    "        super().__init__()\n",
    "        ih, iw = image_size\n",
    "        block = {'C': MBConv, 'T': Transformer}\n",
    "\n",
    "        self.s0 = self._make_layer(\n",
    "            conv_3x3_bn, in_channels, channels[0], num_blocks[0], (ih // 2, iw // 2))\n",
    "        self.s1 = self._make_layer(\n",
    "            block[block_types[0]], channels[0], channels[1], num_blocks[1], (ih // 4, iw // 4))\n",
    "        self.s2 = self._make_layer(\n",
    "            block[block_types[1]], channels[1], channels[2], num_blocks[2], (ih // 8, iw // 8))\n",
    "        self.s3 = self._make_layer(\n",
    "            block[block_types[2]], channels[2], channels[3], num_blocks[3], (ih // 16, iw // 16))\n",
    "        self.s4 = self._make_layer(\n",
    "            block[block_types[3]], channels[3], channels[4], num_blocks[4], (ih // 32, iw // 32))\n",
    "\n",
    "        self.pool = nn.AvgPool2d(ih // 32, 1)\n",
    "        self.fc = nn.Linear(channels[-1], num_classes, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.s0(x)\n",
    "        x = self.s1(x)\n",
    "        x = self.s2(x)\n",
    "        x = self.s3(x)\n",
    "        x = self.s4(x)\n",
    "\n",
    "        x = self.pool(x).view(-1, x.shape[1])\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "    def _make_layer(self, block, inp, oup, depth, image_size):\n",
    "        layers = nn.ModuleList([])\n",
    "        for i in range(depth):\n",
    "            if i == 0:\n",
    "                layers.append(block(inp, oup, image_size, downsample=True))\n",
    "            else:\n",
    "                layers.append(block(oup, oup, image_size))\n",
    "        return nn.Sequential(*layers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coatnet():\n",
    "    num_blocks = [2, 2, 12, 28, 2]          # L\n",
    "    channels = [192, 192, 384, 768, 1536]   # D\n",
    "    return CoAtNet((224, 224), 3, num_blocks, channels, num_classes=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = torch.randn(1,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = coatnet().to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "output = model(img.to('cuda'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1000])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dbnet",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
