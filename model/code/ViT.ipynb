{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViT.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "1UL7aYP7omP1uJ0UYY3DliZIgLCShWu_8",
      "authorship_tag": "ABX9TyP7KoO7wksObSYl/YOsTCFX",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b16465808f354e838d4e356e9c1fe86e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e5ccc2ecd7f49918defc85b654ace3b",
              "IPY_MODEL_bf8b8e9d626c43649a68d31a48d663d0",
              "IPY_MODEL_acd1f0faf42e450589876e6e489c8a63"
            ],
            "layout": "IPY_MODEL_a59a99021b6d4813a9de08ec59c6a476"
          }
        },
        "0e5ccc2ecd7f49918defc85b654ace3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0ebe6107c77a4ec39b00769e048a9f56",
            "placeholder": "​",
            "style": "IPY_MODEL_396216d4a16941f8ad48666a9b90e3f4",
            "value": "100%"
          }
        },
        "bf8b8e9d626c43649a68d31a48d663d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_55946426ebf6461b9e894c3c5c9f4704",
            "max": 2640397119,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_95a280688a834c3393d3e7b128a5ae2c",
            "value": 2640397119
          }
        },
        "acd1f0faf42e450589876e6e489c8a63": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_462495826496473fad1b52343a431de9",
            "placeholder": "​",
            "style": "IPY_MODEL_bfbd5e62688047da9c57c932d22abba0",
            "value": " 2640397119/2640397119 [02:50&lt;00:00, 16095433.40it/s]"
          }
        },
        "a59a99021b6d4813a9de08ec59c6a476": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0ebe6107c77a4ec39b00769e048a9f56": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "396216d4a16941f8ad48666a9b90e3f4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "55946426ebf6461b9e894c3c5c9f4704": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "95a280688a834c3393d3e7b128a5ae2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "462495826496473fad1b52343a431de9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfbd5e62688047da9c57c932d22abba0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/as9786/ComputerVision/blob/main/ViT.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8qgu6epQne3L",
        "outputId": "b46aaeeb-dda4-4ce1-b2e1-e783a1bafe20"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting einops\n",
            "  Downloading einops-0.4.1-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: einops\n",
            "Successfully installed einops-0.4.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "k8WiTsFxnCB9"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "from torch import optim\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader\n",
        "import os\n",
        "from torchvision import utils\n",
        "\n",
        "\n",
        "from torch import nn\n",
        "from torch import Tensor\n",
        "from PIL import Image\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from torchsummary import summary\n",
        "import numpy as np\n",
        "import time\n",
        "import copy\n",
        "import random\n",
        "from tqdm.notebook import tqdm\n",
        "import math"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path2data = '/content/data'\n",
        "\n",
        "# if not exists the path, make the directory\n",
        "if not os.path.exists(path2data):\n",
        "    os.mkdir(path2data)\n",
        "\n",
        "# load dataset\n",
        "train_ds = datasets.STL10(path2data, split='train', download=True, transform=transforms.ToTensor())\n",
        "val_ds = datasets.STL10(path2data, split='test', download=True, transform=transforms.ToTensor())\n",
        "\n",
        "print(len(train_ds))\n",
        "print(len(val_ds))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 141,
          "referenced_widgets": [
            "b16465808f354e838d4e356e9c1fe86e",
            "0e5ccc2ecd7f49918defc85b654ace3b",
            "bf8b8e9d626c43649a68d31a48d663d0",
            "acd1f0faf42e450589876e6e489c8a63",
            "a59a99021b6d4813a9de08ec59c6a476",
            "0ebe6107c77a4ec39b00769e048a9f56",
            "396216d4a16941f8ad48666a9b90e3f4",
            "55946426ebf6461b9e894c3c5c9f4704",
            "95a280688a834c3393d3e7b128a5ae2c",
            "462495826496473fad1b52343a431de9",
            "bfbd5e62688047da9c57c932d22abba0"
          ]
        },
        "id": "G10bJ0RnrZ4M",
        "outputId": "855c1e59-60da-4e40-ee64-f34c1a397f0b"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://ai.stanford.edu/~acoates/stl10/stl10_binary.tar.gz to /content/data/stl10_binary.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/2640397119 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b16465808f354e838d4e356e9c1fe86e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting /content/data/stl10_binary.tar.gz to /content/data\n",
            "Files already downloaded and verified\n",
            "5000\n",
            "8000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# define transformation\n",
        "transformation = transforms.Compose([\n",
        "                    transforms.ToTensor(),\n",
        "                    transforms.Resize(224)\n",
        "])\n",
        "\n",
        "# apply transformation to dataset\n",
        "train_ds.transform = transformation\n",
        "val_ds.transform = transformation\n",
        "\n",
        "# make dataloade\n",
        "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
        "val_dl = DataLoader(val_ds, batch_size=64, shuffle=True)"
      ],
      "metadata": {
        "id": "PPQs0rlirg60"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Embedding"
      ],
      "metadata": {
        "id": "I0vRnw9oniLh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    def __init__(self, in_channels: int = 3, patch_size: int = 16, emb_size: int = 768, img_size: int = 224):\n",
        "        self.patch_size = patch_size\n",
        "        super().__init__()\n",
        "        self.projection = nn.Sequential(\n",
        "            # using a conv layer instead of a linear one -> performance gains\n",
        "            nn.Conv2d(in_channels, emb_size, kernel_size=patch_size, stride=patch_size),\n",
        "            Rearrange('b e (h) (w) -> b (h w) e'),\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.randn(1,1, emb_size))\n",
        "        self.positions = nn.Parameter(torch.randn((img_size // patch_size) **2 + 1, emb_size))\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        b, _, _, _ = x.shape\n",
        "        x = self.projection(x)\n",
        "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
        "        # prepend the cls token to the input\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        # add position embedding\n",
        "        x += self.positions\n",
        "        return x"
      ],
      "metadata": {
        "id": "NWuEoYcsoO-a"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size: int = 768, num_heads: int = 8, dropout: float = 0):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        # fuse the queries, keys and values in one matrix\n",
        "        self.qkv = nn.Linear(emb_size, emb_size * 3)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.projection = nn.Linear(emb_size, emb_size)\n",
        "        \n",
        "    def forward(self, x , mask= None):\n",
        "        # split keys, queries and values in num_heads\n",
        "        qkv = rearrange(self.qkv(x), \"b n (h d qkv) -> (qkv) b h n d\", h=self.num_heads, qkv=3)\n",
        "        queries, keys, values = qkv[0], qkv[1], qkv[2]\n",
        "        # sum up over the last axis\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys) # batch, num_heads, query_len, key_len\n",
        "        if mask is not None:\n",
        "            fill_value = torch.finfo(torch.float32).min\n",
        "            energy.mask_fill(~mask, fill_value)\n",
        "            \n",
        "        scaling = self.emb_size ** (1/2)\n",
        "        att = F.softmax(energy, dim=-1) / scaling\n",
        "        att = self.att_drop(att)\n",
        "        # sum up over the third axis\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "ww1EASTfotQ_"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FeedForwardBlock(nn.Sequential):\n",
        "    def __init__(self, emb_size: int, expansion: int = 4, drop_p: float = 0.):\n",
        "        super().__init__(\n",
        "            nn.Linear(emb_size, expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_p),\n",
        "            nn.Linear(expansion * emb_size, emb_size),\n",
        "        )"
      ],
      "metadata": {
        "id": "h_H-fgN4pqTl"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualAdd(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "        \n",
        "    def forward(self, x, **kwargs):\n",
        "        res = x\n",
        "        x = self.fn(x, **kwargs)\n",
        "        x += res\n",
        "        return x"
      ],
      "metadata": {
        "id": "5HDiQoQsp1Us"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 emb_size: int = 768,\n",
        "                 drop_p: float = 0.,\n",
        "                 forward_expansion: int = 4,\n",
        "                 forward_drop_p: float = 0.,\n",
        "                 ** kwargs):\n",
        "        super().__init__(\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                MultiHeadAttention(emb_size, **kwargs),\n",
        "                nn.Dropout(drop_p)\n",
        "            )),\n",
        "            ResidualAdd(nn.Sequential(\n",
        "                nn.LayerNorm(emb_size),\n",
        "                FeedForwardBlock(\n",
        "                    emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "                nn.Dropout(drop_p)\n",
        "            )\n",
        "            ))"
      ],
      "metadata": {
        "id": "kdDxQSfGp36y"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, depth: int = 12, **kwargs):\n",
        "        super().__init__(*[TransformerEncoderBlock(**kwargs) for _ in range(depth)])"
      ],
      "metadata": {
        "id": "9pvvzCvsqAKW"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ClassificationHead(nn.Sequential):\n",
        "    def __init__(self, emb_size: int = 768, n_classes: int = 1000):\n",
        "        super().__init__(\n",
        "            Reduce('b n e -> b e', reduction='mean'),\n",
        "            nn.LayerNorm(emb_size), \n",
        "            nn.Linear(emb_size, n_classes))"
      ],
      "metadata": {
        "id": "pefvCwiDqBgG"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ViT(nn.Sequential):\n",
        "    def __init__(self,     \n",
        "                in_channels: int = 3,\n",
        "                patch_size: int = 16,\n",
        "                emb_size: int = 768,\n",
        "                img_size: int = 224,\n",
        "                depth: int = 12,\n",
        "                n_classes: int = 1000,\n",
        "                **kwargs):\n",
        "        super().__init__(\n",
        "            PatchEmbedding(in_channels, patch_size, emb_size, img_size),\n",
        "            TransformerEncoder(depth, emb_size=emb_size, **kwargs),\n",
        "            ClassificationHead(emb_size, n_classes)\n",
        "        )"
      ],
      "metadata": {
        "id": "1q_PtBKiqDBt"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(ViT(), (3, 224, 224), device='cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lPIgtffZqE5M",
        "outputId": "680fba76-2a3b-43e2-f431-a977589af608"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 768, 14, 14]         590,592\n",
            "         Rearrange-2             [-1, 196, 768]               0\n",
            "    PatchEmbedding-3             [-1, 197, 768]               0\n",
            "         LayerNorm-4             [-1, 197, 768]           1,536\n",
            "            Linear-5            [-1, 197, 2304]       1,771,776\n",
            "           Dropout-6          [-1, 8, 197, 197]               0\n",
            "            Linear-7             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-8             [-1, 197, 768]               0\n",
            "           Dropout-9             [-1, 197, 768]               0\n",
            "      ResidualAdd-10             [-1, 197, 768]               0\n",
            "        LayerNorm-11             [-1, 197, 768]           1,536\n",
            "           Linear-12            [-1, 197, 3072]       2,362,368\n",
            "             GELU-13            [-1, 197, 3072]               0\n",
            "          Dropout-14            [-1, 197, 3072]               0\n",
            "           Linear-15             [-1, 197, 768]       2,360,064\n",
            "          Dropout-16             [-1, 197, 768]               0\n",
            "      ResidualAdd-17             [-1, 197, 768]               0\n",
            "        LayerNorm-18             [-1, 197, 768]           1,536\n",
            "           Linear-19            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-20          [-1, 8, 197, 197]               0\n",
            "           Linear-21             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-22             [-1, 197, 768]               0\n",
            "          Dropout-23             [-1, 197, 768]               0\n",
            "      ResidualAdd-24             [-1, 197, 768]               0\n",
            "        LayerNorm-25             [-1, 197, 768]           1,536\n",
            "           Linear-26            [-1, 197, 3072]       2,362,368\n",
            "             GELU-27            [-1, 197, 3072]               0\n",
            "          Dropout-28            [-1, 197, 3072]               0\n",
            "           Linear-29             [-1, 197, 768]       2,360,064\n",
            "          Dropout-30             [-1, 197, 768]               0\n",
            "      ResidualAdd-31             [-1, 197, 768]               0\n",
            "        LayerNorm-32             [-1, 197, 768]           1,536\n",
            "           Linear-33            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-34          [-1, 8, 197, 197]               0\n",
            "           Linear-35             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-36             [-1, 197, 768]               0\n",
            "          Dropout-37             [-1, 197, 768]               0\n",
            "      ResidualAdd-38             [-1, 197, 768]               0\n",
            "        LayerNorm-39             [-1, 197, 768]           1,536\n",
            "           Linear-40            [-1, 197, 3072]       2,362,368\n",
            "             GELU-41            [-1, 197, 3072]               0\n",
            "          Dropout-42            [-1, 197, 3072]               0\n",
            "           Linear-43             [-1, 197, 768]       2,360,064\n",
            "          Dropout-44             [-1, 197, 768]               0\n",
            "      ResidualAdd-45             [-1, 197, 768]               0\n",
            "        LayerNorm-46             [-1, 197, 768]           1,536\n",
            "           Linear-47            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-48          [-1, 8, 197, 197]               0\n",
            "           Linear-49             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-50             [-1, 197, 768]               0\n",
            "          Dropout-51             [-1, 197, 768]               0\n",
            "      ResidualAdd-52             [-1, 197, 768]               0\n",
            "        LayerNorm-53             [-1, 197, 768]           1,536\n",
            "           Linear-54            [-1, 197, 3072]       2,362,368\n",
            "             GELU-55            [-1, 197, 3072]               0\n",
            "          Dropout-56            [-1, 197, 3072]               0\n",
            "           Linear-57             [-1, 197, 768]       2,360,064\n",
            "          Dropout-58             [-1, 197, 768]               0\n",
            "      ResidualAdd-59             [-1, 197, 768]               0\n",
            "        LayerNorm-60             [-1, 197, 768]           1,536\n",
            "           Linear-61            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-62          [-1, 8, 197, 197]               0\n",
            "           Linear-63             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-64             [-1, 197, 768]               0\n",
            "          Dropout-65             [-1, 197, 768]               0\n",
            "      ResidualAdd-66             [-1, 197, 768]               0\n",
            "        LayerNorm-67             [-1, 197, 768]           1,536\n",
            "           Linear-68            [-1, 197, 3072]       2,362,368\n",
            "             GELU-69            [-1, 197, 3072]               0\n",
            "          Dropout-70            [-1, 197, 3072]               0\n",
            "           Linear-71             [-1, 197, 768]       2,360,064\n",
            "          Dropout-72             [-1, 197, 768]               0\n",
            "      ResidualAdd-73             [-1, 197, 768]               0\n",
            "        LayerNorm-74             [-1, 197, 768]           1,536\n",
            "           Linear-75            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-76          [-1, 8, 197, 197]               0\n",
            "           Linear-77             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-78             [-1, 197, 768]               0\n",
            "          Dropout-79             [-1, 197, 768]               0\n",
            "      ResidualAdd-80             [-1, 197, 768]               0\n",
            "        LayerNorm-81             [-1, 197, 768]           1,536\n",
            "           Linear-82            [-1, 197, 3072]       2,362,368\n",
            "             GELU-83            [-1, 197, 3072]               0\n",
            "          Dropout-84            [-1, 197, 3072]               0\n",
            "           Linear-85             [-1, 197, 768]       2,360,064\n",
            "          Dropout-86             [-1, 197, 768]               0\n",
            "      ResidualAdd-87             [-1, 197, 768]               0\n",
            "        LayerNorm-88             [-1, 197, 768]           1,536\n",
            "           Linear-89            [-1, 197, 2304]       1,771,776\n",
            "          Dropout-90          [-1, 8, 197, 197]               0\n",
            "           Linear-91             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-92             [-1, 197, 768]               0\n",
            "          Dropout-93             [-1, 197, 768]               0\n",
            "      ResidualAdd-94             [-1, 197, 768]               0\n",
            "        LayerNorm-95             [-1, 197, 768]           1,536\n",
            "           Linear-96            [-1, 197, 3072]       2,362,368\n",
            "             GELU-97            [-1, 197, 3072]               0\n",
            "          Dropout-98            [-1, 197, 3072]               0\n",
            "           Linear-99             [-1, 197, 768]       2,360,064\n",
            "         Dropout-100             [-1, 197, 768]               0\n",
            "     ResidualAdd-101             [-1, 197, 768]               0\n",
            "       LayerNorm-102             [-1, 197, 768]           1,536\n",
            "          Linear-103            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-104          [-1, 8, 197, 197]               0\n",
            "          Linear-105             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-106             [-1, 197, 768]               0\n",
            "         Dropout-107             [-1, 197, 768]               0\n",
            "     ResidualAdd-108             [-1, 197, 768]               0\n",
            "       LayerNorm-109             [-1, 197, 768]           1,536\n",
            "          Linear-110            [-1, 197, 3072]       2,362,368\n",
            "            GELU-111            [-1, 197, 3072]               0\n",
            "         Dropout-112            [-1, 197, 3072]               0\n",
            "          Linear-113             [-1, 197, 768]       2,360,064\n",
            "         Dropout-114             [-1, 197, 768]               0\n",
            "     ResidualAdd-115             [-1, 197, 768]               0\n",
            "       LayerNorm-116             [-1, 197, 768]           1,536\n",
            "          Linear-117            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-118          [-1, 8, 197, 197]               0\n",
            "          Linear-119             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-120             [-1, 197, 768]               0\n",
            "         Dropout-121             [-1, 197, 768]               0\n",
            "     ResidualAdd-122             [-1, 197, 768]               0\n",
            "       LayerNorm-123             [-1, 197, 768]           1,536\n",
            "          Linear-124            [-1, 197, 3072]       2,362,368\n",
            "            GELU-125            [-1, 197, 3072]               0\n",
            "         Dropout-126            [-1, 197, 3072]               0\n",
            "          Linear-127             [-1, 197, 768]       2,360,064\n",
            "         Dropout-128             [-1, 197, 768]               0\n",
            "     ResidualAdd-129             [-1, 197, 768]               0\n",
            "       LayerNorm-130             [-1, 197, 768]           1,536\n",
            "          Linear-131            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-132          [-1, 8, 197, 197]               0\n",
            "          Linear-133             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-134             [-1, 197, 768]               0\n",
            "         Dropout-135             [-1, 197, 768]               0\n",
            "     ResidualAdd-136             [-1, 197, 768]               0\n",
            "       LayerNorm-137             [-1, 197, 768]           1,536\n",
            "          Linear-138            [-1, 197, 3072]       2,362,368\n",
            "            GELU-139            [-1, 197, 3072]               0\n",
            "         Dropout-140            [-1, 197, 3072]               0\n",
            "          Linear-141             [-1, 197, 768]       2,360,064\n",
            "         Dropout-142             [-1, 197, 768]               0\n",
            "     ResidualAdd-143             [-1, 197, 768]               0\n",
            "       LayerNorm-144             [-1, 197, 768]           1,536\n",
            "          Linear-145            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-146          [-1, 8, 197, 197]               0\n",
            "          Linear-147             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-148             [-1, 197, 768]               0\n",
            "         Dropout-149             [-1, 197, 768]               0\n",
            "     ResidualAdd-150             [-1, 197, 768]               0\n",
            "       LayerNorm-151             [-1, 197, 768]           1,536\n",
            "          Linear-152            [-1, 197, 3072]       2,362,368\n",
            "            GELU-153            [-1, 197, 3072]               0\n",
            "         Dropout-154            [-1, 197, 3072]               0\n",
            "          Linear-155             [-1, 197, 768]       2,360,064\n",
            "         Dropout-156             [-1, 197, 768]               0\n",
            "     ResidualAdd-157             [-1, 197, 768]               0\n",
            "       LayerNorm-158             [-1, 197, 768]           1,536\n",
            "          Linear-159            [-1, 197, 2304]       1,771,776\n",
            "         Dropout-160          [-1, 8, 197, 197]               0\n",
            "          Linear-161             [-1, 197, 768]         590,592\n",
            "MultiHeadAttention-162             [-1, 197, 768]               0\n",
            "         Dropout-163             [-1, 197, 768]               0\n",
            "     ResidualAdd-164             [-1, 197, 768]               0\n",
            "       LayerNorm-165             [-1, 197, 768]           1,536\n",
            "          Linear-166            [-1, 197, 3072]       2,362,368\n",
            "            GELU-167            [-1, 197, 3072]               0\n",
            "         Dropout-168            [-1, 197, 3072]               0\n",
            "          Linear-169             [-1, 197, 768]       2,360,064\n",
            "         Dropout-170             [-1, 197, 768]               0\n",
            "     ResidualAdd-171             [-1, 197, 768]               0\n",
            "          Reduce-172                  [-1, 768]               0\n",
            "       LayerNorm-173                  [-1, 768]           1,536\n",
            "          Linear-174                 [-1, 1000]         769,000\n",
            "================================================================\n",
            "Total params: 86,415,592\n",
            "Trainable params: 86,415,592\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.57\n",
            "Forward/backward pass size (MB): 364.33\n",
            "Params size (MB): 329.65\n",
            "Estimated Total Size (MB): 694.56\n",
            "----------------------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ],
      "metadata": {
        "id": "8RMvK9h2rG3g"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = ViT().to(device)"
      ],
      "metadata": {
        "id": "4xdlSV4QqxmT"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loss_func = nn.CrossEntropyLoss(reduction='sum')\n",
        "opt = optim.Adam(model.parameters(),lr=0.01)"
      ],
      "metadata": {
        "id": "8yOm9_lFqG3d"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
        "lr_scheduler = ReduceLROnPlateau(opt, mode='min', factor=0.1, patience=10)"
      ],
      "metadata": {
        "id": "mcRb0sMgqmhI"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_lr(opt):\n",
        "    for param_group in opt.param_groups:\n",
        "        return param_group['lr']"
      ],
      "metadata": {
        "id": "gSIyoZdPrMuZ"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def metric_batch(output, target):\n",
        "    pred = output.argmax(1, keepdim=True)\n",
        "    corrects = pred.eq(target.view_as(pred)).sum().item()\n",
        "    return corrects\n",
        "\n",
        "\n",
        "# calculate the loss per mini-batch\n",
        "def loss_batch(loss_func, output, target, opt=None):\n",
        "    loss_b = loss_func(output, target)\n",
        "    metric_b = metric_batch(output, target)\n",
        "\n",
        "    if opt is not None:\n",
        "        opt.zero_grad()\n",
        "        loss_b.backward()\n",
        "        opt.step()\n",
        "    \n",
        "    return loss_b.item(), metric_b\n",
        "\n",
        "\n",
        "# calculate the loss per epochs\n",
        "def loss_epoch(model, loss_func, dataset_dl, sanity_check=False, opt=None):\n",
        "    running_loss = 0.0\n",
        "    running_metric = 0.0\n",
        "    len_data = len(dataset_dl.dataset)\n",
        "\n",
        "    for xb, yb in dataset_dl:\n",
        "        xb = xb.to(device)\n",
        "        yb = yb.to(device)\n",
        "        output = model(xb)\n",
        "\n",
        "        loss_b, metric_b = loss_batch(loss_func, output, yb, opt)\n",
        "\n",
        "        running_loss += loss_b\n",
        "        \n",
        "        if metric_b is not None:\n",
        "            running_metric += metric_b\n",
        "\n",
        "        if sanity_check is True:\n",
        "            break\n",
        "\n",
        "    loss = running_loss / len_data\n",
        "    metric = running_metric / len_data\n",
        "    return loss, metric"
      ],
      "metadata": {
        "id": "-KOpJIR_rOFb"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_val(model, params):\n",
        "    num_epochs=params['num_epochs']\n",
        "    loss_func=params['loss_func']\n",
        "    opt=params['optimizer']\n",
        "    train_dl=params['train_dl']\n",
        "    val_dl=params['val_dl']\n",
        "    sanity_check=params['sanity_check']\n",
        "    lr_scheduler=params['lr_scheduler']\n",
        "    path2weights=params['path2weights']\n",
        "\n",
        "    loss_history = {'train': [], 'val': []}\n",
        "    metric_history = {'train': [], 'val': []}\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    start_time = time.time()\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        current_lr = get_lr(opt)\n",
        "        print('Epoch {}/{}, current lr= {}'.format(epoch, num_epochs-1, current_lr))\n",
        "\n",
        "        model.train()\n",
        "        train_loss, train_metric = loss_epoch(model, loss_func, train_dl, sanity_check, opt)\n",
        "        loss_history['train'].append(train_loss)\n",
        "        metric_history['train'].append(train_metric)\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_loss, val_metric = loss_epoch(model, loss_func, val_dl, sanity_check)\n",
        "        loss_history['val'].append(val_loss)\n",
        "        metric_history['val'].append(val_metric)\n",
        "\n",
        "        if val_loss < best_loss:\n",
        "            best_loss = val_loss\n",
        "            best_model_wts = copy.deepcopy(model.state_dict())\n",
        "            torch.save(model.state_dict(), path2weights)\n",
        "            print('Copied best model weights!')\n",
        "\n",
        "        lr_scheduler.step(val_loss)\n",
        "        if current_lr != get_lr(opt):\n",
        "            print('Loading best model weights!')\n",
        "            model.load_state_dict(best_model_wts)\n",
        "\n",
        "        print('train loss: %.6f, val loss: %.6f, accuracy: %.2f, time: %.4f min' %(train_loss, val_loss, 100*val_metric, (time.time()-start_time)/60))\n",
        "        print('-'*10)\n",
        "\n",
        "    model.load_state_dict(best_model_wts)\n",
        "    return model, loss_history, metric_history"
      ],
      "metadata": {
        "id": "Bj6VuaZmrPos"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params_train = {\n",
        "    'num_epochs':100,\n",
        "    'optimizer':opt,\n",
        "    'loss_func':loss_func,\n",
        "    'train_dl':train_dl,\n",
        "    'val_dl':val_dl,\n",
        "    'sanity_check':False,\n",
        "    'lr_scheduler':lr_scheduler,\n",
        "    'path2weights':'./models/weights.pt',\n",
        "}\n",
        "\n",
        "# check the directory to save weights.pt\n",
        "def createFolder(directory):\n",
        "    try:\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "    except OSerror:\n",
        "        print('Error')\n",
        "createFolder('./models')"
      ],
      "metadata": {
        "id": "6WMx2KIYrRom"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model, loss_hist, metric_hist = train_val(model, params_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVewhptnrTeJ",
        "outputId": "667ebb42-7c21-4436-f07a-ef84278a644b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 0/99, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 2.835725, val loss: 2.326060, accuracy: 17.25, time: 4.4190 min\n",
            "----------\n",
            "Epoch 1/99, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 2.211852, val loss: 2.116819, accuracy: 16.59, time: 8.8789 min\n",
            "----------\n",
            "Epoch 2/99, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 2.079534, val loss: 2.010430, accuracy: 19.68, time: 13.3487 min\n",
            "----------\n",
            "Epoch 3/99, current lr= 0.01\n",
            "train loss: 2.037880, val loss: 2.036775, accuracy: 20.46, time: 17.8106 min\n",
            "----------\n",
            "Epoch 4/99, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 1.995252, val loss: 1.967762, accuracy: 20.69, time: 22.2982 min\n",
            "----------\n",
            "Epoch 5/99, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 1.981146, val loss: 1.920916, accuracy: 26.06, time: 26.7800 min\n",
            "----------\n",
            "Epoch 6/99, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 1.940076, val loss: 1.867093, accuracy: 25.26, time: 31.2586 min\n",
            "----------\n",
            "Epoch 7/99, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 1.894280, val loss: 1.859214, accuracy: 28.45, time: 35.7210 min\n",
            "----------\n",
            "Epoch 8/99, current lr= 0.01\n",
            "Copied best model weights!\n",
            "train loss: 1.889382, val loss: 1.805936, accuracy: 29.05, time: 40.1844 min\n",
            "----------\n",
            "Epoch 9/99, current lr= 0.01\n",
            "train loss: 1.930305, val loss: 1.913192, accuracy: 25.70, time: 44.6233 min\n",
            "----------\n",
            "Epoch 10/99, current lr= 0.01\n",
            "train loss: 2.027950, val loss: 1.918561, accuracy: 25.46, time: 49.0430 min\n",
            "----------\n",
            "Epoch 11/99, current lr= 0.01\n",
            "train loss: 1.956582, val loss: 1.848583, accuracy: 26.88, time: 53.4723 min\n",
            "----------\n",
            "Epoch 12/99, current lr= 0.01\n",
            "train loss: 2.170266, val loss: 2.085053, accuracy: 15.81, time: 57.8864 min\n",
            "----------\n",
            "Epoch 13/99, current lr= 0.01\n",
            "train loss: 2.051055, val loss: 1.970326, accuracy: 21.73, time: 62.3134 min\n",
            "----------\n",
            "Epoch 14/99, current lr= 0.01\n",
            "train loss: 2.107175, val loss: 2.077342, accuracy: 19.25, time: 66.7381 min\n",
            "----------\n",
            "Epoch 15/99, current lr= 0.01\n",
            "train loss: 1.988026, val loss: 2.119957, accuracy: 17.82, time: 71.1531 min\n",
            "----------\n",
            "Epoch 16/99, current lr= 0.01\n",
            "train loss: 1.964087, val loss: 1.919783, accuracy: 23.86, time: 75.5704 min\n",
            "----------\n",
            "Epoch 17/99, current lr= 0.01\n",
            "train loss: 1.937169, val loss: 1.897056, accuracy: 25.25, time: 79.9888 min\n",
            "----------\n",
            "Epoch 18/99, current lr= 0.01\n",
            "train loss: 1.939695, val loss: 1.942442, accuracy: 21.85, time: 84.4220 min\n",
            "----------\n",
            "Epoch 19/99, current lr= 0.01\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Io_me90zsgeB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
