{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/trocr/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import VisionEncoderDecoderModel, AutoTokenizer, TrOCRProcessor\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split\n",
    "import json\n",
    "import os\n",
    "\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 장치"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 사전 학습 모형 불러오기\n",
    "model = VisionEncoderDecoderModel.from_pretrained(\"team-lucid/trocr-small-korean\").to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전처리 도구\n",
    "processor = TrOCRProcessor.from_pretrained(\"team-lucid/trocr-small-korean\")\n",
    "tokenizer = AutoTokenizer.from_pretrained('team-lucid/trocr-small-korean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOLO 사용 시 불러오기\n",
    "#yolo = YOLO('/workspace/ojt/OCR/YOLO/runs/detect/best_yolov8n/weights/best.pt').to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 학습 가중치 불러오기\n",
    "model.load_state_dict(torch.load('/workspace/ojt/OCR/TrOCR/save_point_28.pth'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 추론할 사진 폴더 \n",
    "imgs = sorted(glob('/workspace/ojt/OCR/dataset/infer_final/image/*'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/ojt/OCR/dataset/infer_final/image/008b1a0b-2a55-2054-f3bb-fd20f5b69628.jpg',\n",
       " '/workspace/ojt/OCR/dataset/infer_final/image/0de9fdab-1873-a95d-7ebe-19aae551a32d.jpg',\n",
       " '/workspace/ojt/OCR/dataset/infer_final/image/1d99d954-8082-594d-4cb1-eba581e8caef.jpg',\n",
       " '/workspace/ojt/OCR/dataset/infer_final/image/bd036c86-e028-cdbd-e06a-a37f1162816d.jpg',\n",
       " '/workspace/ojt/OCR/dataset/infer_final/image/db4aac6f-0810-0df6-92fa-62cbd1b7cebb.jpg']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "image 1/1 /workspace/ojt/OCR/dataset/infer/imgs/sample3.png: 2048x800 76 Texts, 72.0ms\n",
      "Speed: 7.4ms preprocess, 72.0ms inference, 1.4ms postprocess per image at shape (1, 3, 2048, 800)\n"
     ]
    }
   ],
   "source": [
    "# YOLO를 사용할 경우 YOLO 결과\n",
    "#results = yolo(imgs[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/workspace/ojt/OCR/CRAFT-pytorch/result/res_008b1a0b-2a55-2054-f3bb-fd20f5b69628.txt',\n",
       " '/workspace/ojt/OCR/CRAFT-pytorch/result/res_0de9fdab-1873-a95d-7ebe-19aae551a32d.txt',\n",
       " '/workspace/ojt/OCR/CRAFT-pytorch/result/res_1d99d954-8082-594d-4cb1-eba581e8caef.txt',\n",
       " '/workspace/ojt/OCR/CRAFT-pytorch/result/res_bd036c86-e028-cdbd-e06a-a37f1162816d.txt',\n",
       " '/workspace/ojt/OCR/CRAFT-pytorch/result/res_db4aac6f-0810-0df6-92fa-62cbd1b7cebb.txt']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 예측 결과 불러오기\n",
    "bboxes = sorted(glob('/workspace/ojt/OCR/CRAFT-pytorch/result/*txt'))[:5]\n",
    "bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "경계 상자 개수 :  677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/miniconda3/envs/trocr/lib/python3.8/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "56.309916257858276\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "#results = yolo(imgs[2])\n",
    "with open(bboxes[4], 'r') as f:\n",
    "    boxes = f.readlines()\n",
    "boxes = list(map(lambda x: x.strip(), boxes))\n",
    "#boxes = results[0].boxes.xyxy.cpu().numpy()\n",
    "sample = cv2.imread(imgs[4])\n",
    "sample = cv2.cvtColor(sample, cv2.COLOR_BGR2RGB)\n",
    "print('경계 상자 개수 : ',len(boxes))\n",
    "patches = []\n",
    "texts = []\n",
    "for j in range(len(boxes)):\n",
    "    x = boxes[j].split(',')\n",
    "    x = np.array(x,dtype=np.int32)\n",
    "    xs = x[1::2]\n",
    "    ys = x[::2]\n",
    "    min_x = np.min(xs)\n",
    "    max_x = np.max(xs)\n",
    "    min_y = np.min(ys)\n",
    "    max_y = np.max(ys)\n",
    "    patch = sample[min_x : max_x + 1, min_y : max_y + 1,:]\n",
    "    patches.append([min_x,min_y,max_x,max_y])\n",
    "    img = Image.fromarray(patch)\n",
    "    pixel_values =(processor(img,return_tensors='pt').pixel_values).to(device)\n",
    "    generated_ids1 = model.generate(pixel_values)\n",
    "    generated_text1 = tokenizer.batch_decode(generated_ids1, skip_special_tokens=True)[0]\n",
    "    texts.append(generated_text1)\n",
    "print(time.time()-start)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 결과 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import platform\n",
    "from PIL import ImageFont, ImageDraw, Image\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rc('font', family='/workspace/ojt/OCR/TrOCR/malgun.ttf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_values =(processor(img,return_tensors='pt').pixel_values).to(device)\n",
    "generated_ids1 = model.generate(pixel_values)\n",
    "generated_text1 = tokenizer.batch_decode(generated_ids1, skip_special_tokens=True)[0]\n",
    "generated_ids2 = model2.generate(pixel_values)\n",
    "generated_text2 = tokenizer.batch_decode(generated_ids2, skip_special_tokens=True)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "print(generated_text1)\n",
    "print(generated_text2)\n",
    "plt.imshow(np.array(img))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "display-im6.q16: unable to open X server `' @ error/display.c/DisplayImageCommand/412.\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image, ImageDraw, ImageFont\n",
    "\n",
    "image = Image.open(imgs[4]).convert('RGB')\n",
    "# 이미지 크기 설정 (예: 800x600)\n",
    "image_width = image.size[0]\n",
    "image_height = image.size[1]\n",
    "\n",
    "# 주어진 좌표와 텍스트 정보\n",
    "\n",
    "for i in range(len(patches)):\n",
    "    min_x, min_y, max_x, max_y = patches[i][1], patches[i][0], patches[i][3], patches[i][2]\n",
    "    #text = texts[i]\n",
    "    text = texts[i]\n",
    "\n",
    "    # 이미지 생성 (흰색 배경)\n",
    "\n",
    "    draw = ImageDraw.Draw(image)\n",
    "\n",
    "    # 텍스트를 그릴 폰트 설정 (기본 폰트 사용)\n",
    "    font = ImageFont.truetype('/workspace/ojt/OCR/TrOCR/malgun.ttf',size=50)\n",
    "    draw.rectangle([min_x, min_y, max_x, max_y], outline=\"green\", width=10)\n",
    "    # 텍스트 크기 계산\n",
    "    bbox = draw.textbbox((0, 0), text, font=font)\n",
    "    text_width = bbox[2] - bbox[0]\n",
    "    text_height = bbox[3] - bbox[1]\n",
    "\n",
    "    # 텍스트를 그릴 위치 계산 (중앙 정렬)\n",
    "    text_x = min_x + (max_x - min_x - text_width) / 2\n",
    "    text_y = min_y - 30\n",
    "\n",
    "    # 텍스트 그리기\n",
    "    draw.text((text_x, text_y), text, fill=\"blue\", font=font,fontsize=10)\n",
    "\n",
    "    # 이미지 저장\n",
    "image.save(\"output_image3.png\")\n",
    "\n",
    "# 이미지 보기 (선택 사항)\n",
    "image.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1966"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texts_path = glob('/workspace/ojt/OCR/dataset/infer_final/text_files/*')\n",
    "len(texts_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TRAIN_1</td>\n",
       "      <td>./train/TRAIN_1.jpg</td>\n",
       "      <td>식품의</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>TRAIN_2</td>\n",
       "      <td>./train/TRAIN_2.jpg</td>\n",
       "      <td>유형</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>TRAIN_3</td>\n",
       "      <td>./train/TRAIN_3.jpg</td>\n",
       "      <td>커피</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>TRAIN_4</td>\n",
       "      <td>./train/TRAIN_4.jpg</td>\n",
       "      <td>유통기한</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>TRAIN_5</td>\n",
       "      <td>./train/TRAIN_5.jpg</td>\n",
       "      <td>용기</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id             img_path label\n",
       "0  TRAIN_1  ./train/TRAIN_1.jpg   식품의\n",
       "1  TRAIN_2  ./train/TRAIN_2.jpg    유형\n",
       "2  TRAIN_3  ./train/TRAIN_3.jpg    커피\n",
       "3  TRAIN_4  ./train/TRAIN_4.jpg  유통기한\n",
       "4  TRAIN_5  ./train/TRAIN_5.jpg    용기"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('/workspace/ojt/OCR/dataset/infer_final/final_datset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1966 [00:00<?, ?it/s]/root/miniconda3/envs/trocr/lib/python3.8/site-packages/transformers/generation/utils.py:1168: UserWarning: Using the model-agnostic default `max_length` (=20) to control the generation length. We recommend setting `max_new_tokens` to control the maximum length of the generation.\n",
      "  warnings.warn(\n",
      "100%|██████████| 1966/1966 [02:44<00:00, 11.93it/s]\n"
     ]
    }
   ],
   "source": [
    "preds = []\n",
    "for path in tqdm(df.img_path):\n",
    "    new_path = path.replace('./train', '/workspace/ojt/OCR/dataset/infer_final/text_files')\n",
    "    img = Image.open(new_path).convert('RGB')\n",
    "    pixel_values =(processor(img,return_tensors='pt').pixel_values).to(device)\n",
    "    generated_ids1 = model.generate(pixel_values)\n",
    "    generated_text1 = tokenizer.batch_decode(generated_ids1, skip_special_tokens=True)[0]\n",
    "    preds.append(generated_text1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 정확도 계산"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>img_path</th>\n",
       "      <th>label</th>\n",
       "      <th>preds</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>TRAIN_1962</td>\n",
       "      <td>./train/TRAIN_1962.jpg</td>\n",
       "      <td>영양성분</td>\n",
       "      <td>영양성분</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>TRAIN_1963</td>\n",
       "      <td>./train/TRAIN_1963.jpg</td>\n",
       "      <td>기준치에</td>\n",
       "      <td>기준치에</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>TRAIN_1964</td>\n",
       "      <td>./train/TRAIN_1964.jpg</td>\n",
       "      <td>및</td>\n",
       "      <td>및</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>TRAIN_1965</td>\n",
       "      <td>./train/TRAIN_1965.jpg</td>\n",
       "      <td>또는</td>\n",
       "      <td>또는</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>TRAIN_1966</td>\n",
       "      <td>./train/TRAIN_1966.jpg</td>\n",
       "      <td>수</td>\n",
       "      <td>수</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              id                img_path label preds\n",
       "1961  TRAIN_1962  ./train/TRAIN_1962.jpg  영양성분  영양성분\n",
       "1962  TRAIN_1963  ./train/TRAIN_1963.jpg  기준치에  기준치에\n",
       "1963  TRAIN_1964  ./train/TRAIN_1964.jpg     및     및\n",
       "1964  TRAIN_1965  ./train/TRAIN_1965.jpg    또는   또는 \n",
       "1965  TRAIN_1966  ./train/TRAIN_1966.jpg     수     수"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['preds'] = preds \n",
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 0\n",
    "for i in range(len(df)):\n",
    "    if df.loc[i, 'label'].replace(' ','') == df.loc[i, 'preds'].replace(' ',''):\n",
    "        c += 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3387589013224822"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6673448626653102"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c / len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 틀린 결과 보기\n",
    "df[df.label != df.preds].head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trocr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
